# PDF Q&A λ°μ΄ν„°λ¥Ό ν™μ©ν• LLM νμΈνλ‹ κ°€μ΄λ“

μ΄ κ°€μ΄λ“λ” PDFμ—μ„ μ¶”μ¶ν• μ§λ¬Έ-λ‹µλ³€ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬ λ€κ·λ¨ μ–Έμ–΄ λ¨λΈ(LLM)μ„ ν¨μ¨μ μΌλ΅ νμΈνλ‹ν•λ” λ°©λ²•μ„ μ„¤λ…ν•©λ‹λ‹¤. μ €λΉ„μ© κ³ ν¨μ¨μ νμΈνλ‹μ„ μ„ν•΄ LoRA μ–΄λ‘ν„°μ™€ Unsloth μµμ ν™” κΈ°μ μ„ ν™μ©ν•©λ‹λ‹¤.

## π“‹ λ©μ°¨

1. ν™κ²½ μ¤€λΉ„
2. λ°μ΄ν„° μ¤€λΉ„
3. LoRAμ™€ Unsloth
4. λ¨λΈ νμΈνλ‹
5. μ¶”λ΅  λ° ν‰κ°€

## 1. ν™κ²½ μ¤€λΉ„

### ν•„μ λΌμ΄λΈλ¬λ¦¬

νμΈνλ‹μ— ν•„μ”ν• μ£Όμ” λΌμ΄λΈλ¬λ¦¬:
- `torch`: λ”¥λ¬λ‹ ν”„λ μ„μ›ν¬
- `unsloth`: LLM μµμ ν™” λΌμ΄λΈλ¬λ¦¬
- `transformers`: λ¨λΈ λ° ν† ν¬λ‚μ΄μ € λ΅λ“
- `datasets`: λ°μ΄ν„°μ…‹ μ²λ¦¬
- `trl`: μ§€λ„ ν•™μµ νμΈνλ‹(SFTTrainer)

> β οΈ **μ¤‘μ”**: `trl` ν¨ν‚¤μ§€λ” νμΈνλ‹μ„ μ„ν• ν•„μ λΌμ΄λΈλ¬λ¦¬μ…λ‹λ‹¤. SFTTrainer ν΄λμ¤κ°€ μ΄ ν¨ν‚¤μ§€μ— ν¬ν•¨λμ–΄ μμΌλ©°, μ΄ μ—†μ΄λ” μ§€λ„ νμΈνλ‹(Supervised Fine-Tuning)μ„ μν–‰ν•  μ μ—†μµλ‹λ‹¤.

### GPU νΈν™μ„± ν™•μΈ

```python
import torch
major_version, minor_version = torch.cuda.get_device_capability()
```

NVIDIA GPUμ— λ”°λΌ λ‹¤μ–‘ν• λ©”λ¨λ¦¬ μµμ ν™” κΈ°λ²•μ„ μ μ©ν•  μ μμµλ‹λ‹¤:
- Ampere μ•„ν‚¤ν…μ²(A100, A10G λ“±): BFloat16 μ§€μ›
- Tesla/Turing μ•„ν‚¤ν…μ²(T4, V100): Float16 κ¶μ¥

> π’΅ **μ°Έκ³ **: PyTorch λ²„μ „μ— λ”°λΌ ν¨μΉκ°€ ν•„μ”ν•  μ μμµλ‹λ‹¤. PyTorch 2.3 λ―Έλ§ λ²„μ „μ—μ„λ” `torch.amp.is_autocast_available()` API ν¨μΉκ°€ ν•„μ”ν•©λ‹λ‹¤.

## 2. λ°μ΄ν„° μ¤€λΉ„

### Q&A λ°μ΄ν„° κµ¬μ΅°

PDF QA μ¶”μ¶ λ„κµ¬λ΅ μƒμ„±λ JSONL νμΌμ€ λ‹¤μκ³Ό κ°™μ€ κµ¬μ΅°λ¥Ό κ°€μ§‘λ‹λ‹¤:

```json
{
  "instruction": "κΈμµλ³΄μ•κµμ΅μ„Όν„°μ μ£Όμ†λ” μ–΄λ””μΈκ°€μ”?",
  "output": "κΈμµλ³΄μ•κµμ΅μ„Όν„°μ μ£Όμ†λ” μ„μΈνΉλ³„μ‹ μλ“±ν¬κµ¬ μμ‚¬λ‹Ήλ€λ΅ 143 κΈμµν¬μλΉλ”© 12μΈµμ…λ‹λ‹¤."
}
```

### ν•™μµ λ°μ΄ν„° ν¬λ§·ν…

LLM νμΈνλ‹μ„ μ„ν•΄ λ°μ΄ν„°λ¥Ό μ μ ν• ν”„λ΅¬ν”„νΈ ν•μ‹μΌλ΅ λ³€ν™ν•΄μ•Ό ν•©λ‹λ‹¤. μΌλ°μ μΌλ΅ "μ§€μ‹μ‚¬ν•­-μ‘λ‹µ" ν•νƒμ ν…ν”λ¦Ώμ„ μ‚¬μ©ν•λ©°, κ° μμ μ λμ—λ” μΆ…λ£ ν† ν°(EOS)μ„ μ¶”κ°€ν•©λ‹λ‹¤.

## 3. LoRAμ™€ Unsloth

### LoRA(Low-Rank Adaptation) μ΄ν•΄ν•κΈ°

LoRAλ” λ€κ·λ¨ μ–Έμ–΄ λ¨λΈ(LLM)μ„ ν¨μ¨μ μΌλ΅ νμΈνλ‹ν•κΈ° μ„ν• κΈ°μ μ…λ‹λ‹¤:

![LoRA κ°λ…λ„](../assets/images/LORA.png)
*μ°Έμ΅°: Hu, E., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., & Chen, W. (2022). LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS. arXiv.*

**μ£Όμ” νΉμ§•:**
- **ν¨μ¨μ„±**: μ „μ²΄ λ¨λΈ νλΌλ―Έν„°μ μ•½ 1~10%λ§ ν•™μµ
- **μ›λ¦¬**: κ°€μ¤‘μΉ ν–‰λ ¬ λ³€ν™”λ¥Ό μ €μ°¨μ›(low-rank) ν–‰λ ¬μ κ³±μΌλ΅ κ·Όμ‚¬
- **νλΌλ―Έν„°**:
  - `r`: λ­ν¬ ν¬κΈ° (ν΄μλ΅ ν‘ν„λ ¥ β†‘, ν•™μµ νλΌλ―Έν„° β†‘)
  - `alpha`: μ¤μΌ€μΌλ§ νλΌλ―Έν„° (λ³΄ν†µ rμ 2λ°° μ„¤μ •)
  - `target_modules`: μ μ©ν•  λ¨λ“ (μ–΄ν…μ…, FF λ μ΄μ–΄ λ“±)

### Unsloth μµμ ν™” κΈ°μ 

Unslothλ” LLM ν›λ ¨ ν¨μ¨μ„±μ„ κ·Ήλ€ν™”ν•λ” μµμ ν™” λΌμ΄λΈλ¬λ¦¬μ…λ‹λ‹¤:

**ν•µμ‹¬ κΈ°λ¥:**
- **μ»΄ν“¨ν… μµμ ν™”**: CUDA μ»¤λ„ λ° μ£Όμ λ©”μ»¤λ‹μ¦ μµμ ν™”
- **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: "unsloth" λ¨λ“λ΅ VRAM 30% μ¶”κ°€ μ μ•½
- **μ¶”λ΅  κ°€μ†**: FastLanguageModel.for_inference() λ©”μ†λ“λ΅ μƒμ„± μ†λ„ 2λ°° ν–¥μƒ

**μ •λ°€λ„ μ„ νƒ μµμ…:**
- **4λΉ„νΈ μ–‘μν™”** (`load_in_4bit=True`)
  - κ°€μ¥ λ©”λ¨λ¦¬ ν¨μ¨μ μΈ μµμ…μΌλ΅ VRAM μ‚¬μ©λ‰ 80% κ°μ†
  - μµμ†ν•μ VRAMμΌλ΅ ν° λ¨λΈ ν›λ ¨ κ°€λ¥
  - μ•½κ°„μ μ •ν™•λ„ μ†μ‹¤ κ°€λ¥μ„± μμ

- **8λΉ„νΈ μ–‘μν™”** (`load_in_8bit=True`)
  - 4λΉ„νΈλ³΄λ‹¤ μ •ν™•λ„κ°€ λ” μΆ‹μ
  - κ·Έλ¬λ‚ λ” λ§μ€ λ©”λ¨λ¦¬ ν•„μ”
  - μ •ν™•λ„μ™€ λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ κ· ν•μ 

- **16λΉ„νΈ μ •λ°€λ„** (`dtype=torch.float16` λλ” `torch.bfloat16`)
  - κ°€μ¥ λ†’μ€ μ •ν™•λ„
  - κ°€μ¥ λ§μ€ λ©”λ¨λ¦¬ μ‚¬μ©
  - bfloat16μ€ Ampere+ GPUμ—μ„ κ¶μ¥ (A100, A10G, A5000 λ“±)
  - float16μ€ Tesla/Turing GPUμ—μ„ κ¶μ¥ (T4, V100)

- **μλ™ κ°μ§€** (`dtype=None`)
  - GPU νƒ€μ…μ— λ”°λΌ μ μ ν• μ •λ°€λ„ μλ™ μ„ νƒ

**μ μ© μ‹ μ΄μ :**
- μΌλ° LoRAλ³΄λ‹¤ 2-3λ°° λΉ λ¥Έ ν•™μµ μ†λ„
- 8GB VRAMμΌλ΅λ„ 7B λ¨λΈ νμΈνλ‹ κ°€λ¥
- λ™μΌ ν•λ“μ›¨μ–΄μ—μ„ λ” ν° λ°°μΉ ν¬κΈ° μ‚¬μ© κ°€λ¥

## 4. λ¨λΈ νμΈνλ‹

### νμΈνλ‹ μ£Όμ” λ‹¨κ³„

1. **λ¨λΈ λ΅λ“**: μ μ ν• μ •λ°€λ„ μµμ…μΌλ΅ κΈ°λ³Έ λ¨λΈκ³Ό ν† ν¬λ‚μ΄μ €λ¥Ό λ΅λ“ν•©λ‹λ‹¤.

2. **LoRA μ–΄λ‘ν„° μ„¤μ •**: μ–΄λ‘ν„°μ λ­ν¬, νƒ€κ² λ¨λ“, λ“λ΅­μ•„μ›ƒ λ“±μ„ μ„¤μ •ν•©λ‹λ‹¤.

3. **SFTTrainer κµ¬μ„±**: ν•™μµλ¥ , λ°°μΉ ν¬κΈ°, μ—ν­, λ©”λ¨λ¦¬ μµμ ν™” μµμ… λ“±μ ν›λ ¨ νλΌλ―Έν„°λ¥Ό μ„¤μ •ν•©λ‹λ‹¤.

4. **λ¨λΈ ν›λ ¨ λ° μ €μ¥**: μ¤€λΉ„λ μ„¤μ •μΌλ΅ λ¨λΈμ„ ν›λ ¨ν•κ³  κ²°κ³Όλ¥Ό μ €μ¥ν•©λ‹λ‹¤.

```python
# λ¨λΈ λ΅λ“ μ‹ μ •λ°€λ„ μµμ… μμ‹
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="beomi/Llama-3-Open-Ko-8B-Instruct-preview",
    max_seq_length=4096,
    
    # μ•„λ μ •λ°€λ„ μµμ… μ¤‘ ν•λ‚ μ„ νƒ
    load_in_4bit=True,                # 4λΉ„νΈ μ–‘μν™” (μµμ† VRAM)
    # load_in_8bit=True,              # 8λΉ„νΈ μ–‘μν™” (μ¤‘κ°„ VRAM)
    # dtype=torch.float16,            # Float16 μ •λ°€λ„ (T4/V100)
    # dtype=torch.bfloat16,           # BFloat16 μ •λ°€λ„ (A100/A10G)
    # dtype=None,                     # μλ™ κ°μ§€
)

model = FastLanguageModel.get_peft_model(
    model,
    r=16,                             # LoRA λ­ν¬
    use_gradient_checkpointing="unsloth"  # λ©”λ¨λ¦¬ μµμ ν™”
)
```

### κ¶μ¥ νλΌλ―Έν„° μ„¤μ •

| νλΌλ―Έν„° | κ¶μ¥ κ°’ | μ„¤λ… |
|----------|---------|------|
| r | 8~64 | μ‘μ„μλ΅ λ©”λ¨λ¦¬ ν¨μ¨μ , ν΄μλ΅ μ„±λ¥ ν–¥μƒ |
| lora_alpha | 2r | μΌλ°μ μΌλ΅ λ­ν¬μ 2λ°°λ΅ μ„¤μ • |
| learning_rate | 2e-4~1e-5 | ν° κ°’μ€ λΉ λ¥Έ ν•™μµ, μ‘μ€ κ°’μ€ μ•μ •μ  ν•™μµ |
| batch_size | 1~8 | VRAMμ— λ§κ² μ΅°μ • (gradient_accumulation_stepsμ™€ ν•¨κ») |

## 5. μ¶”λ΅  λ° ν‰κ°€

### λ¨λΈ μ¶”λ΅  μµμ ν™”

Unslothλ” μ¶”λ΅  μ†λ„λ„ μµμ ν™”ν•©λ‹λ‹¤:

```python
# μ¶”λ΅  κ°€μ†ν™”
FastLanguageModel.for_inference(model)
```

μ΄ μ„¤μ •μΌλ΅ ν† ν° μƒμ„± μ†λ„κ°€ μ•½ 2λ°° ν–¥μƒλ©λ‹λ‹¤.

### μ‹¤μ  μ‚¬μ© μμ‹

νμΈνλ‹λ λ¨λΈμ€ ν…ν”λ¦Ώ ν•μ‹μ— λ§μ¶° μ§λ¬Έμ„ μ κ³µν•λ©΄ ν•™μµλ μ§€μ‹μ„ κΈ°λ°μΌλ΅ μ‘λ‹µμ„ μƒμ„±ν•©λ‹λ‹¤. μλ¥Ό λ“¤μ–΄ "κΈμµλ³΄μ•κµμ΅μ„Όν„°μ μ£Όμ†?"λΌλ” μ§λ¬Έμ„ μ…λ ¥ν•λ©΄, PDFμ—μ„ μ¶”μ¶λ μ •λ³΄λ¥Ό λ°”νƒ•μΌλ΅ μ •ν™•ν• μ£Όμ†λ¥Ό μ‘λ‹µν•  μ μμµλ‹λ‹¤.

## π’΅ μµμ ν™” μ „λµ λ° κ³ κΈ‰ ν

### GPU λ©”λ¨λ¦¬ μµμ ν™”

- **μ •λ°€λ„ μ„ νƒ**: ν•λ“μ›¨μ–΄μ™€ μ”κµ¬μ‚¬ν•­μ— λ”°λΌ μ μ ν• μ •λ°€λ„ μ„ νƒ
  - μ ν•λ VRAM (8-12GB): 4λΉ„νΈ μ–‘μν™” μ‚¬μ©
  - μ¤‘κ°„ VRAM (16-24GB): 8λΉ„νΈ μ–‘μν™” κ³ λ ¤
  - μ¶©λ¶„ν• VRAM (32GB+): 16λΉ„νΈ μ •λ°€λ„λ΅ μµμƒμ μ„±λ¥ ν™•λ³΄
- **gradient_checkpointing**: ν™μ„±ν™” μ‹ 30% μ¶”κ°€ VRAM μ μ•½
- **batch_sizeμ™€ gradient_accumulation_steps**: κ³±μ΄ κ°™μΌλ©΄ λ™μΌν• ν¨κ³Ό, λ‚λ μ„ λ©”λ¨λ¦¬ μ΅°μ 

### λ¨λΈ μ„ νƒ μ „λµ

- **μ†ν• λ¨λΈ(~7B)**: λ¦¬μ†μ¤ μ μ•½ ν™κ²½μ— μ ν•©, λΉ λ¥Έ λ°λ³µ κ°€λ¥
- **ν•κµ­μ–΄ νΉν™” λ¨λΈ**: Llama-3-Open-Ko-8B λ“± ν•κµ­μ–΄ μ²λ¦¬μ— κ°•μ 
- **νΉμ • λ„λ©”μΈ λ¨λΈ**: κΈμµ, λ²•λ¥  λ“± νΉμ • λ¶„μ•Όμ— μ‚¬μ „ ν•™μµλ λ¨λΈ μ„ νƒ

### ν–¥ν›„ λ°μ΄ν„° ν’μ§ ν–¥μƒ λ°©λ²•

- **PDF QA μ¶”μ¶ νλΌλ―Έν„° μ΅°μ •**: μ¶”μ¶ ν’μ§ ν–¥μƒμΌλ΅ ν•™μµ λ°μ΄ν„° ν’μ§ κ°μ„ 
- **μ—­μ „ν ν•™μµ(Backtranlation)**: λ™μΌ κ°λ…μ— λ€ν• λ‹¤μ–‘ν• ν‘ν„ μƒμ„±μΌλ΅ λ°μ΄ν„° μ¦κ°•
- **λ°μ΄ν„° ν•„ν„°λ§**: μ¤‘λ³µ, λ¶λ…ν™•ν• QA μ μ κ±°λ΅ ν’μ§ ν–¥μƒ


## π’΅ μ£Όμ” μ”μ 

- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: NλΉ„νΈ μ–‘μν™”μ™€ LoRA μ–΄λ‘ν„°λ΅ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ†ν™”
- **λΉ λ¥Έ ν›λ ¨ μ†λ„**: Unsloth μµμ ν™”λ¥Ό ν†µν•΄ κΈ°μ΅΄ λ€λΉ„ 2λ°° μ΄μƒ λΉ λ¥Έ ν›λ ¨ μ†λ„
- **ν•κµ­μ–΄ νΉν™”**: ν•κµ­μ–΄ κΈ°λ° λ¨λΈμ„ μ‚¬μ©ν•μ—¬ μ°μν• μ‘λ‹µ ν’μ§
- **κ°„νΈν• κµ¬ν„**: μ „μ²΄ νμ΄ν”„λΌμΈμ΄ λ…ν™•ν•κ² μ •μλμ–΄ μ‰½κ² κµ¬ν„ κ°€λ¥

## π” μ£Όμμ‚¬ν•­

1. **trl ν¨ν‚¤μ§€ ν•„μ**: SFTTrainerλ¥Ό μ‚¬μ©ν•κΈ° μ„ν•΄ trl ν¨ν‚¤μ§€κ°€ λ°λ“μ‹ μ„¤μΉλμ–΄μ•Ό ν•©λ‹λ‹¤. μ—†μΌλ©΄ νμΈνλ‹ κ³Όμ •μ΄ μ‘λ™ν•μ§€ μ•μµλ‹λ‹¤.
2. **GPU μ”κµ¬μ‚¬ν•­**: μµμ† 12GB VRAMμ΄ κ¶μ¥λ©λ‹λ‹¤. λ” μ‘μ€ GPUμ—μ„λ” batch size μ΅°μ •μ΄ ν•„μ”ν•©λ‹λ‹¤.
3. **λ°μ΄ν„° ν’μ§**: νμΈνλ‹ κ²°κ³Όλ” λ°μ΄ν„° ν’μ§μ— ν¬κ² μμ΅΄ν•©λ‹λ‹¤. κ³ ν’μ§ Q&A λ°μ΄ν„°λ¥Ό μ¤€λΉ„ν•μ„Έμ”.
---

μ΄ κ°€μ΄λ“λ¥Ό ν†µν•΄ PDFμ—μ„ μ¶”μ¶ν• Q&A λ°μ΄ν„°λ΅ ν¨μ¨μ μΈ LLM νμΈνλ‹μ„ μν–‰ν•  μ μμµλ‹λ‹¤. LoRA μ–΄λ‘ν„°μ™€ Unsloth μµμ ν™”λ¥Ό κ²°ν•©ν•λ©΄ μ ν•λ μ»΄ν“¨ν… μμ›μΌλ΅λ„ νΉμ • λ„λ©”μΈμ— μµμ ν™”λ κ³ μ„±λ¥ λ¨λΈμ„ κµ¬μ¶•ν•  μ μμµλ‹λ‹¤. μ •λ°€λ„ μµμ…μ„ μ μ ν μ„ νƒν•μ—¬ μ‚¬μ© κ°€λ¥ν• ν•λ“μ›¨μ–΄ μμ›κ³Ό λ¨λΈ μ„±λ¥ κ°„μ μµμ μ κ· ν•μ„ μ°Ύμ„ μ μμµλ‹λ‹¤.